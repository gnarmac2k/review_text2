{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a102e3f6-39ae-45f7-88f0-e5da06d2a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from pathlib import Path\n",
    "from transformers import BertTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbaced78-9840-4c76-b43b-a7ee2c4e102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('movie_corpora.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07b4143d-ca2f-4d5b-901e-1b0e731185e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 Cloverfield Lane 2016</td>\n",
       "      <td>movie full suspense makes guess real happens w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 Things I Hate About You 1999</td>\n",
       "      <td>first day new school cameron falls bianca stra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12 Angry Men 1957</td>\n",
       "      <td>excellent courtroom drama unique twist instead...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Movie Name  \\\n",
       "0         10 Cloverfield Lane 2016   \n",
       "1  10 Things I Hate About You 1999   \n",
       "2                12 Angry Men 1957   \n",
       "\n",
       "                                              Corpus  \n",
       "0  movie full suspense makes guess real happens w...  \n",
       "1  first day new school cameron falls bianca stra...  \n",
       "2  excellent courtroom drama unique twist instead...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d5e0cec-2df0-4ebb-9600-9388ff9c2596",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d1efab7-91d0-4e39-95bf-643ee004ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the 'Corpus' column\n",
    "df['Tokenized Corpus'] = df['Corpus'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6daffa2d-0840-4b78-85d0-04fdf1e4a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already tokenized the data and it's stored in the 'Tokenized Corpus' column\n",
    "\n",
    "# Save the DataFrame with the tokenized data to a new CSV file\n",
    "df.to_csv('tokenized_movie_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9be75a2-0866-4aac-8bf1-f0f194caba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Loading Pretrained Model\n",
    "from transformers import BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f5b70ef-1985-4e43-949f-418ed6b7793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BERT model\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36c0735c-91c0-4a5f-b78c-e1027bab35fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Embedding Extraction\n",
    "\n",
    "# Convert token IDs to tensors\n",
    "input_ids = torch.tensor(df['Tokenized Corpus'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e566e80-ef65-4cfb-aab6-e61da8815265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass through the model to get embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6438f322-10ed-43a4-965d-fd80a05b58e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings from the last layer\n",
    "embeddings = outputs.last_hidden_state[:, 0, :].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "863b7cfd-b910-484b-8af9-312ac5da1a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Similarity Computation\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64667882-c95c-4f57-ba6e-5da12754d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between movies\n",
    "similarity_matrix = cosine_similarity(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc179ce5-8648-45b5-bb96-777d75682bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Clustering or Visualization\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee90193c-2b1f-4b64-9c11-5f4e6e031b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard McConkie\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\Richard McConkie\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cluster the movies\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "clusters = kmeans.fit_predict(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c0153ef-d98a-4f27-a2c1-7bd3c78fff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Interpretation and Evaluation\n",
    "# You can examine the clusters to see if they make sense in terms of movie similarity\n",
    "\n",
    "# Step 7: Application\n",
    "# Use the similarity analysis for your desired applications (e.g., movie recommendations)\n",
    "\n",
    "# Optionally, you can save the results back to the DataFrame\n",
    "df['Cluster'] = clusters\n",
    "\n",
    "# Optionally, save the DataFrame with clusters\n",
    "df.to_csv('movies_with_clusters.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e159f308-0103-4f7b-8113-007526e0c7de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d8561-fcaf-4d3f-ad36-f1be8c94a02a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39efc16-798c-4565-8583-e9be17f503f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
